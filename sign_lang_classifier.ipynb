{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spiritual-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exotic-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if gpu is available\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surgical-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-haiti",
   "metadata": {},
   "source": [
    "## Making Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-methodology",
   "metadata": {},
   "source": [
    "<b>Dataset info</b> :<br><t><p>\n",
    "    ``ASL dataset created by B. Kang et al is used. It is a collection of 31,000 images, 1000 images for each of the 31 classes. These gestures are recorded for a total of five subjects. The gestures include numerals 1- 9 and alphabets A-Z except ‘J’ and ‘Z’, because these require movements of hand and thus cannot be captured in the form of an image. Some of the gestures are very similar, (0/o) , (V/2) and (W/6). These are classified by context or meaning.``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "infrared-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(dir):   # Finds the class folders in a dataset, dir (string): Root directory path.\n",
    "\n",
    "        classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "large-girlfriend",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASLDataset(Dataset):\n",
    "    \"\"\" American Sign Language Dataset \"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, classes, class_to_idx, path):\n",
    "        \n",
    "        self.image_paths = image_paths\n",
    "        self.transforms = transforms.ToTensor()\n",
    "        self.class_to_idx = class_to_idx\n",
    "        classes, class_to_idx = find_classes(path)\n",
    "       \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = Image.open(self.image_paths[index])\n",
    "        transform_image = image.convert(\"L\")\n",
    "        transform_image = self.transforms(transform_image)\n",
    "        \n",
    "        class_to_idx = self.class_to_idx\n",
    "        \n",
    "        return transform_image, class_to_idx, self.image_paths[index]\n",
    "        \n",
    "    def __len__(self): \n",
    "\n",
    "        return len(self.image_paths)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-description",
   "metadata": {},
   "source": [
    "### Setting data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "responsible-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/nayugartx8/Desktop/Aayush_work/Sign_language_model/Train/*/*.*'\n",
    "folder_data = glob.glob(path)\n",
    "np.savetxt('distribution_class.csv', np.c_[folder_data], fmt=['%s'], comments='', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "homeless-beach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data = len(folder_data)\n",
    "len_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blank-parker",
   "metadata": {},
   "source": [
    "Splits : 60 % Train, 20 % validation, 10% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "billion-twenty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52200, 69600)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_1 = int(0.6 * len(folder_data))\n",
    "split_2 = int(0.8 * len(folder_data))\n",
    "\n",
    "split_1, split_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powerful-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of train images is:  52200\n"
     ]
    }
   ],
   "source": [
    "folder_data.sort()\n",
    "\n",
    "train_image_paths = folder_data[:split_1]\n",
    "print(\"count of train images is: \", len(train_image_paths)) \n",
    "np.savetxt('im_training_path_1.csv', np.c_[train_image_paths], fmt=['%s'], comments='', delimiter = \",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "finite-green",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of validation images is:  17400\n"
     ]
    }
   ],
   "source": [
    "valid_image_paths = folder_data[split_1:split_2]\n",
    "print(\"count of validation images is: \", len(valid_image_paths)) \n",
    "np.savetxt('im_validation_path_1.csv', np.c_[valid_image_paths], fmt=['%s'], comments='', delimiter = \",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handy-ozone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of test images is:  17400\n"
     ]
    }
   ],
   "source": [
    "test_image_paths = folder_data[split_2:]\n",
    "print(\"count of test images is: \", len(test_image_paths)) \n",
    "np.savetxt('im_testing_path_1.csv', np.c_[test_image_paths], fmt=['%s'], comments='', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broadband-sustainability",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A',\n",
       "  'B',\n",
       "  'C',\n",
       "  'D',\n",
       "  'E',\n",
       "  'F',\n",
       "  'G',\n",
       "  'H',\n",
       "  'I',\n",
       "  'J',\n",
       "  'K',\n",
       "  'L',\n",
       "  'M',\n",
       "  'N',\n",
       "  'O',\n",
       "  'P',\n",
       "  'Q',\n",
       "  'R',\n",
       "  'S',\n",
       "  'T',\n",
       "  'U',\n",
       "  'V',\n",
       "  'W',\n",
       "  'X',\n",
       "  'Y',\n",
       "  'Z',\n",
       "  'del',\n",
       "  'nothing',\n",
       "  'space'],\n",
       " {'A': 0,\n",
       "  'B': 1,\n",
       "  'C': 2,\n",
       "  'D': 3,\n",
       "  'E': 4,\n",
       "  'F': 5,\n",
       "  'G': 6,\n",
       "  'H': 7,\n",
       "  'I': 8,\n",
       "  'J': 9,\n",
       "  'K': 10,\n",
       "  'L': 11,\n",
       "  'M': 12,\n",
       "  'N': 13,\n",
       "  'O': 14,\n",
       "  'P': 15,\n",
       "  'Q': 16,\n",
       "  'R': 17,\n",
       "  'S': 18,\n",
       "  'T': 19,\n",
       "  'U': 20,\n",
       "  'V': 21,\n",
       "  'W': 22,\n",
       "  'X': 23,\n",
       "  'Y': 24,\n",
       "  'Z': 25,\n",
       "  'del': 26,\n",
       "  'nothing': 27,\n",
       "  'space': 28})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Label and Label map\n",
    "\n",
    "classes = sorted([subfolder for subfolder in os.listdir('./Train')])\n",
    "classes_to_idx = {i: j for j, i in enumerate(classes)}\n",
    "classes, classes_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecological-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = '/home/nayugartx8/Desktop/Aayush_work/Sign_language_model/Train/'\n",
    "train_dataset = ASLDataset(train_image_paths, classes_to_idx, classes, paths)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mature-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = ASLDataset(valid_image_paths,  classes_to_idx, classes,paths)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "test_dataset = ASLDataset(test_image_paths, classes_to_idx, classes, paths)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "israeli-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoaders = {\n",
    "        'train': train_loader,\n",
    "        'valid': valid_loader,\n",
    "         'test': test_loader,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-height",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
